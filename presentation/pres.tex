\documentclass[10pt,presentation,color=names]{beamer}
\usepackage{etex}
\usetheme{boxes}

\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{itemize items}{$\cdot$}
\setbeamertemplate{footline}[frame number]

\usepackage[all]{xy}
\usepackage{proof}

\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{stmaryrd}
\usepackage{latexsym} % for nicer \leadsto
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english]{babel}

\usefonttheme{professionalfonts}
\renewcommand{\sfdefault}{\rmdefault}

\newcommand{\Fomega}{\mathtt{F}_\omega}

\newcommand{\Typevars}{\mathcal{A}}
\newcommand{\Vars}{\mathcal{V}}
\newcommand{\Rules}{\mathcal{R}}
\newcommand{\Iterms}{\mathcal{I}}
\newcommand{\ITypes}{\mathcal{Y}}

\newcommand{\arrkind}{\Rightarrow}
\newcommand{\arrtype}{\rightarrow}
\newcommand{\quant}[2]{\forall #1.#2}

\newcommand{\abstraction}[2]{\backslash #1.#2}
\newcommand{\app}[2]{#1 \cdot #2}
\newcommand{\tapp}[2]{#1 * #2}
\newcommand{\subst}[2]{#1:=#2}

\newcommand{\abs}[2]{\lambda #1.#2}
\newcommand{\tabs}[2]{\Lambda #1.#2}
\newcommand{\pair}[2]{\langle #1,#2 \rangle}
\newcommand{\expair}[2]{[#1,#2]}

\newcommand{\arrW}{\leadsto}
\newcommand{\arr}[1]{\longrightarrow_{#1}}
\newcommand{\red}{\longrightarrow}
\newcommand{\arrrbeta}{\arrW_\beta^*}

\newcommand{\nat}{\mathtt{nat}}
\newcommand{\flatten}{\mathtt{flatten}}
\newcommand{\lift}{\mathtt{lift}}

\newcommand{\typeinterpret}[1]{\llbracket #1 \rrbracket}
\newcommand{\interpret}[1]{\llbracket #1 \rrbracket}
\newcommand{\itp}[1]{\llbracket #1 \rrbracket}

\newcommand{\refsec}[1]{Section~\ref{sec:#1}}

\newcommand{\FTV}{\mathrm{FTV}}
\newcommand{\FV}{\mathrm{FV}}
\newcommand{\Tc}{\mathcal{T}}
\newcommand{\Vc}{\mathcal{V}}
\newcommand{\Xc}{\mathcal{X}}
\newcommand{\WM}{\mathcal{W\!M}}

\newcommand{\cl}{\mathcal{C}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\nf}{\mathrm{nf}}

\newcommand{\da}{\mathord{\downarrow}}
\newcommand{\SN}{\mathrm{SN}}
\newcommand{\Cb}{\mathbb{C}}
\newcommand{\Nbb}{\mathbb{N}}
\newcommand{\val}[3]{\ensuremath{\llbracket#1\rrbracket_{#2}^{#3}}}
\newcommand{\gteq}[3]{\ensuremath{\ge_{#1}^{#2,#3}}}

\newcommand{\Typemap}{\mathcal{T\!M}}
\newcommand{\Termmap}{\mathcal{J}}
\newcommand{\succinterpret}{\succ^{\Termmap}}
\newcommand{\succeqinterpret}{\succeq^{\Termmap}}

\newcommand{\symb}[1]{\textcolor{blue}{\mathtt{#1}}}
\newcommand{\var}[1]{\textcolor{red}{#1}}
\newcommand{\binder}[1]{\textcolor{purple}{#1}}

\newcommand{\List}{\mathtt{List}}
\newcommand{\Pair}{\mathtt{Pair}}
\newcommand{\Nat}{\mathtt{Nat}}
\newcommand{\nil}{\symb{nil}}
\newcommand{\cons}{\symb{cons}}
\newcommand{\map}{\symb{map}}
\newcommand{\fold}{\symb{fold}}
\newcommand{\xlet}[4]{\mathtt{let}_{#1}\,#2\,\mathtt{be}\,[#3]\,\mathtt{in}\,#4}
\newcommand{\proj}{\symb{pr}}

\newcommand{\CK}[1]{\textcolor{violet}{CK: #1}}
\newcommand{\CKchange}[1]{\textcolor{blue}{#1}}
\newcommand{\LC}[1]{\textcolor{red}{LC: #1}}
\newcommand{\LCchange}[1]{\textcolor{red}{#1}}

\title{Polymorphic Higher-order Termination}

\author{\L{}ukasz Czajka, TU Dortmund University\\Cynthia Kop, Radboud University Nijmegen}

\date{June 2019}

\begin{document}
\maketitle

\begin{frame}{Polynomial interpretations: first-order}

%STORY: talk about TRSs and what we mean by termination .
%STORY: introduce polynomial interpretations as one of the oldest techniques to prove it.
%STORY: discuss on a high level how the interpretation given here works.

\textbf{Question:} Does the following TRS terminate?
\[
\begin{array}{rcl}
\symb{append}(\nil, \var{ys}) & \red & \var{ys} \\
\symb{append}(\cons(\var{x},\var{xs}),\var{ys}) & \red & \cons(\var{x},\symb{append}(\var{xs},\var{ys})) \\
\end{array}
\]

\ \\\pause
\textbf{Answer:} Yes, it does. \pause
Let:
\[
\begin{array}{rcl}
\interpret{\nil} & = & 1 \\
\interpret{\cons}(s,t) & = & 1 + \interpret{s} + \interpret{t} \\
\interpret{\symb{append}}(s,t) & = & 2 * \interpret{s} + \interpret{t} \\
\end{array}
\]
\pause Then:
\[
\begin{array}{rcl}
\interpret{\symb{append}(\nil, \var{ys})} & = & 2 + \var{ys} \\
  & > & \var{ys} \\
  & = & \interpret{\var{ys}} \\\
\interpret{\symb{append}(\cons(\var{x},\var{xs}),\var{ys})} & = & 2 + 2\var{x} + 2\var{xs} + ys \\
  & > & 1 + \var{x} + 2\var{xs} + \var{ys} \\
  & = & \interpret{\cons(\var{x},\symb{append}(\var{xs},\var{ys}))} \\
\end{array}
\]
\end{frame}

%CK: Note that I chose map rather than fold because there is no polynomial interpretation for
%    monomorphic fold -- at least, not in the earlier definitions. There may be one with our
%    definitions; that I do not know.
%LC: Well, monomorphic fold should be just a modification of our fold
%    example from the paper (I mean, using our framework -- you need
%    the encodings of inductive data types; you can define lists with
%    a fixed type of elements analogously to homogeneous polymorphic
%    lists)
\begin{frame}{Polynomial interpretations: higher-order}

\textbf{Question:} Does the following higher-order TRS terminate?
\[
\begin{array}{rcl}
\map(\var{F},\nil) & \red & \nil \\
\map(\var{F},\cons(\var{x},\var{xs})) & \red & \cons(\var{F} \cdot \var{x},\map(\var{F},\var{xs})) \\
\end{array}
\]

\ \\\pause
\textbf{Answer:} Depends. \pause
%STORY: Would it surprise you if I told you that this might actually be non-terminating?
\alert{Not} terminating if:
\[
\begin{array}{rcl}
\nil & : & \mathtt{o} \\
\cons & : & (\mathtt{o} \arrtype \mathtt{o}) \arrtype \mathtt{o} \arrtype \mathtt{o} \\
\map & : & ((\mathtt{o} \arrtype \mathtt{o}) \arrtype \mathtt{o}) \arrtype \mathtt{o} \arrtype \mathtt{o} \\
\end{array}
\]
\LC{The types don't match! $\var{F} : (o \to o) \to o$, $x : o \to o$,
  so $\var{F} x : o$, but the first argument of $\cons$ expects $o \to
  o$. I don't understand what you wanted to write here.}

% LC: maybe we can just say that if we consider this untyped, then it doesn't terminate?

%STORY: Types are important; especially when you have lambda-abstraction, you have to be careful. With the given typing, the rules above can be used to encode the untyped lambda-calculus. This is exemplified by the following non-terminating term.
%NOTE: This would be told very quickly, to show to the RTA crowd why types are important; however, I do not want to waste too much time on it as it's not the point of the talk.
%It's not the point of this talk, after all -- but does help to illustrate to the RTA part of the audience why we look at types so much.
\ \\\pause
Let $\omega := \cons(\abs{\binder{x}:o}{\map(\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \binder{x}},\binder{x})},\nil)$. Then:
\[
\begin{array}{ll}
& \map(\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \omega},\omega) \\
\red & \cons(\ (\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \omega})\
  (\abs{\binder{x}:o}{\map(\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \binder{x}},\binder{x})})\ , \map(\dots)) \\
\red_\beta & \cons(\ (\abs{\binder{x}:o}{\map(\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \binder{x}},\binder{x})})\ \omega\ , \map(\dots)) \\
\red_\beta & \cons(\ \underline{\map(\abs{\binder{y}:\mathtt{o} \arrtype \mathtt{o}}{\binder{y}\ \omega},\omega)}\ , \map(\dots)) \\
\end{array}
\]
\ \\
\ \\
\ \\
\ \\
\ \\
\ \\
\end{frame}

\begin{frame}{Polynomial interpretations: higher-order}

%STORY: If the types work out, we can try to use the same idea for higher-order rewriting, as seen for instance in functional programming and various proof systems.
%STORY: Here give a very rough sketch of Jaco's work.

\textbf{Question:} Does the following higher-order TRS terminate?
\[
\begin{array}{rcl}
\map(\var{F},\nil) & \red & \nil \\
\map(\var{F},\cons(\var{x},\var{xs})) & \red & \cons(\var{F} \cdot \var{x},\map(\var{F},\var{xs})) \\
\end{array}
\]

\ \\
\textbf{Answer:} Depends. \pause It \alert{does} terminate if:
\[
\begin{array}{rcl}
\nil & : & \List \\
\cons & : & \Nat \arrtype \List \arrtype \List \\
\map & : & (\Nat \arrtype \Nat) \arrtype \List \arrtype \List \\
\end{array}
\]

\pause Let:
\[
\begin{array}{rcl}
\interpret{\nil} & = & 0 \\
\interpret{\cons(s,t)} & = & 1 + \interpret{s} + \interpret{t} \\
\interpret{\map(s,t)} & = & (2 + \interpret{t}) * (1 + \interpret{s}(\interpret{t})) \\
\interpret{s\ t} & = & \interpret{s}(\interpret{t}) + \interpret{t}\ \ \text{if}\ s : \Nat \arrtype \Nat \\
\end{array}
\]

\pause Then:
\[
\begin{array}{rcl}
\interpret{\map(\var{F},\nil)} & = & \var{F}(0) + 1 \\
 & > & 0 = \interpret{\nil} \\
\interpret{\map(\var{F},\cons(\var{x},\var{xs}))} & = &
  (2 + \var{F}(1 + \var{x} + \var{xs})) * (2 + \var{x} + \var{xs}) \\
  & > & 1 + \var{F}(\var{x}) + \var{x} + (2 + \var{xs}) * (1 + \var{F}(\var{xs})) \\
  & = & \interpret{\cons(\var{F} \cdot \var{x},\map(\var{F},\var{xs}))} \\
\end{array}
\]

\end{frame}

\begin{frame}{Polynomial interpretations: polymorphic higher-order}

%STORY: Let's take this a step further and go for a polymorphic system. This is the kind of polymorphism that we see in ML-like language.

\textbf{Question:} Does the following polymorphic HO-TRS terminate?
\[
\begin{array}{rcl}
\map(\var{F},\nil) & \red & \nil \\
\map(\var{F},\cons(\var{x},\var{xs})) & \red & \cons(\var{F} \cdot \var{x},\map(\var{F},\var{xs})) \\
\end{array}
\]
\[
\begin{array}{rcll}
\nil & : & \forall \alpha. & \List(\alpha) \\
\cons & : & \forall \alpha. & \alpha \arrtype \List(\alpha) \arrtype \List(\alpha) \\
\map & : & \forall \alpha \beta. & (\alpha \arrtype \beta) \arrtype \List(\alpha) \arrtype \List(\beta) \\
\end{array}
\]

%STORY: Now, it actually is terminating, and we could see that by considering all possible type instances. Let's look at another example.
\pause\ \\
\textbf{Question:} What about the following?
\[
\begin{array}{rcl}
\fold(\var{F},\var{a},\nil) & \red & \var{a} \\
\fold(\var{F},\var{a},\cons(\var{x},\var{xs})) & \red & \fold(\var{F},\var{F}\ \var{a}\ \var{x},\var{xs})
\end{array}
\]
\[
\begin{array}{rcll}
\fold & : & \forall \alpha \beta . & (\beta \arrtype \alpha \arrtype \beta) \arrtype \beta \arrtype \List(\alpha) \arrtype \beta \\
\end{array}
\]
%STORY: Note that this example is somewhat different than map, because a functional variable is applied repeatedly on the same item; that is, you build a term like F^n(x).
%STORY: This cannot be handled with the "higher-order polynomial" interpretations from the last slide, although arguably that's just a weakness of that definition of polynomials.
\end{frame}

\begin{frame}{Shallow vs.\ Higher-rank polymorphism}
\textbf{Shallow polymorphism:}
\[
\begin{array}{rcllr}
\uncover<2->{\List} & \uncover<2->{:} & \multicolumn{2}{l}{\uncover<2->{* \arrtype *}} & \uncover<2>{\alert{\Longleftarrow}} \\
\nil & : & \forall \alpha. & \List(\alpha) \\
\cons & : & \forall \alpha. & \alpha \arrtype \List(\alpha) \arrtype \List(\alpha) \\
\fold & : & \forall \alpha \beta . & (\beta \arrtype \alpha \arrtype \beta) \arrtype \beta \arrtype \List(\alpha) \arrtype \beta \\
\end{array}
\]
\[
\begin{array}{rclr}
\fold_{\only<2->{\tau,\sigma}}(\var{F},\var{a},\nil_{\only<2->{\tau}}) & \red & \var{a} & \uncover<2>{\alert{\Longleftarrow}} \\
\fold_{\only<2->{\tau,\sigma}}(\var{F},\var{a},\cons_{\only<2->{\tau}}(\var{x},\var{xs})) & \red
  & \fold_{\only<2->{\tau,\sigma}}(\var{F},\var{F}\ \var{a}\ \var{x},\var{xs}) & \uncover<2>{\alert{\Longleftarrow}} \\
\end{array}
\]

\pause\pause\ \\
\textbf{Higher-rank polymorphism:}
\[
\begin{array}{rcllr}
\List & : & & * \\
\nil & : & & \List \\
\cons & : & \forall \alpha. & \alpha \arrtype \List \arrtype \List \\
\fold & : & \forall \beta . & (\forall \alpha . \beta \arrtype \alpha \arrtype \beta) \arrtype \beta \arrtype \List \arrtype \beta \\
\end{array}
\]
\[
\begin{array}{rclr}
\fold_{\sigma}(\var{F},\var{a},\nil) & \red & \var{a} & \uncover<2>{\alert{\Longleftarrow}} \\
\fold_{\sigma}(\var{F},\var{a},\cons_{\tau}(\var{x},\var{xs})) & \red & \fold_{\sigma}(\var{F},\var{F}\ \tau\ \var{a}\ \var{x},\var{xs}) \\
\end{array}
\]

%STORY: Here make sure to discuss the application domains: Haskell, logic.
\end{frame}

\begin{frame}{Our goal: handle systems like this!}
\framesubtitle{Polymorphic functional systems}

%STORY: There are many ways to formalise systems like this; we use the following because it's convenient:
\begin{itemize}
\item Function symbols have a type: $\forall \alpha_1 \dots \alpha_n.\sigma_1 \arrtype \dots \arrtype \sigma_k \arrtype \tau$
\item Terms are variables, abstractions, type (constructor) abstractions and: $\symb{f}_{\pi_1,\dots,\pi_n}(s_1,\dots,s_k) : \tau[\alpha_1:=\pi_1,\dots,\alpha_n:=\pi_n]$.
\item Variables and abstractions at the head of a term \emph{not
  allowed}: $\lambda x . x t$, $(\lambda x . t) u$. \pause
%STORY: Okay, so what does this mean for the fold system that we just saw?
%STORY: (before the first pause) This is what we had, but note that we have those applications there.
%STORY: (before the second pause) So, we introduce function symbols for application and type application, and corresponding rules.
%STORY: (before the third pause) Then, we replace the applications and type applications accordingly.
\[
\begin{array}{rcllrl}
\List & : & & * \\
\nil & : & & \List \\
\cons & : & \forall \alpha. & \alpha \arrtype \List \arrtype \List \\
\fold & : & \forall \beta . & (\forall \alpha . \beta \arrtype \alpha \arrtype \beta) \arrtype \beta \arrtype \List \arrtype \beta \\
\uncover<3->{\symb{@}} & \uncover<3->{:} & \uncover<3->{\forall \alpha\forall \beta. & (\alpha \arrtype \beta) \arrtype (\alpha \arrtype \beta)} &
  \uncover<3>{\alert{\Longleftarrow}} \\
\uncover<3->{\symb{tapp}} & \uncover<3->{:} & \uncover<3->{\forall \alpha : * \arrkind *.\forall \beta.} & \uncover<3->{(\forall \gamma.\alpha\gamma) \arrtype \alpha\beta} &
  \uncover<3>{\alert{\Longleftarrow}} \\
\end{array}
\]
\[
\begin{array}{rcll}
\fold_{\sigma}(\var{F},\var{a},\nil) & \red & \var{a} \\
\fold_{\sigma}(\var{F},\var{a},\cons_{\tau}(\var{x},\var{xs})) & \red & \uncover<1-3>{\fold_{\sigma}(\var{F},\var{F}\ \tau\ \var{a}\ \var{x},\var{xs})} \\
  \multicolumn{4}{r}{\uncover<4->{
    \fold_{\sigma}(\var{F},\symb{@}_{\tau,\sigma}(\symb{@}_{\sigma,\tau \arrtype \sigma}(\symb{tapp}_{\lambda \alpha.\sigma \arrtype \alpha \arrtype \sigma,\tau}(\var{F}), \var{a}), \var{x}),\var{xs})
  }} \\
\uncover<3->{\symb{@}_{\sigma,\tau}(\abs{x:\sigma.s},t)} & \uncover<3->{\red} & \uncover<3->{s[x:=t]} &
  \uncover<3>{\alert{\Longleftarrow}} \\
\uncover<3->{\symb{tapp}_{\lambda \alpha.\sigma,\tau}(\tabs{\alpha}{s})} & \uncover<3->{\red} & \uncover<3->{s[\alpha:=\tau]} &
  \uncover<3>{\alert{\Longleftarrow}} \\
\end{array}
\]
%LC: STORY: the type of tapp quantifies of a type constructor alpha
%(this type constructor is a ``function'' from a type to a type); this
%is why we need F-omega and not only system F
%STORY: This is not a natural formalism. It doesn't need to be: it is just meant to define the method. Real polymorphic systems would be translated into it.
\item\pause\pause\pause \textbf{\alert{Note:} not meant as a formalism of interest by itself, but only as a tool to analyse polymorphic systems.}
\end{itemize}
\end{frame}

\begin{frame}{Monomorphic higher-order algebras [Pol96]}

\textbf{Idea:}
\begin{itemize}
\item Choose a set $\mathcal{A}$ with well-founded ordering $\succ$.
\item Define:
  \begin{itemize}
  \item $\WM_{\kappa} = \mathcal{A}$ if $\kappa$ is a \alert{base type}
  \item $\WM_{\sigma \arrtype \tau} = \{ f \in \WM_\sigma \Longrightarrow \WM_\tau \mid f\ \text{is weakly monotonic} \}$.
  \end{itemize}
\item Terms of type $\sigma$ are mapped to $\WM_\Sigma$.
\end{itemize}

\ \\\textbf{Natural choice:} natural numbers

\end{frame}

\begin{frame}{Monomorphic higher-order algebras [Pol96]}

\[
\begin{array}{rcl}
\map(\var{F},\nil) & \red & \nil \\
\map(\var{F},\cons(\var{x},\var{xs})) & \red & \cons(\var{F} \cdot \var{x},\map(\var{F},\var{xs})) \\
\end{array}
\]
\[
\begin{array}{rcl}
\nil & : & \List \\
\cons & : & \Nat \arrtype \List \arrtype \List \\
\map & : & (\Nat \arrtype \Nat) \arrtype \List \arrtype \List \\
\end{array}
\]

\ \\\textbf{Interpretation to $\mathbb{N}$:}
\begin{itemize}
\item\pause $\WM_{\List} = \WM_{\Nat} = \mathbb{N}$
  %STORY: point at for instance list, x and xs, but also at the whole terms
\item\pause $\WM_{\Nat \arrtype \Nat} = \{$weakly monotonic functions from $\mathbb{N}$ to $\mathbb{N}\}$
  %STORY: point at the variable F
\item\pause $\WM_{\Nat \arrtype \List \arrtype \List} = \{$weakly monotonic functions from $\mathbb{N} \times \mathbb{N}$ to $\mathbb{N}\}$
  %STORY: point at the function symbol cons
\item\pause $\WM_{(\Nat \arrtype \Nat) \arrtype \List \arrtype \List} = \{$weakly monotonic functionals from $\WM_{\Nat \arrtype \Nat} \times \mathbb{N}$ to $\mathbb{N}\}$
  %STORY: point at the function symbol map
\end{itemize}

\end{frame}

\begin{frame}{Monomorphic higher-order polynomial interpretations [FuhKop12]}

\textbf{Interpretation:}
\[
\begin{array}{rcl}
\interpret{\nil} & = & 0 \\
\interpret{\cons(s,t)} & = & 1 + \interpret{s} + \interpret{t} \\
\interpret{\map(s,t)} & = & (2 + \interpret{t}) * (1 + \interpret{s}(\interpret{t})) \\
\interpret{s\ t} & = & \interpret{s}(\interpret{t}) + \interpret{t}\ \ \text{if}\ s : \Nat \arrtype \Nat \\
\end{array}
\]

\pause\ \\\textbf{Put differently:}
\[
\begin{array}{rcl}
\interpret{\nil} & = & 0 \\
\interpret{\cons} & = & \lambda x y.1 + x + y \\
\interpret{\map} & = & \lambda f x.(2 + x) * (1 + f(x)) \\
\interpret{@_{\Nat,\Nat}} & = & \lambda f x.f(x) + x \\
\end{array}
\]

\end{frame}

\begin{frame}{Polymorphic higher-order interpretations (our work)}

\begin{itemize}
\item Problem: set-theoretic interpretation \alert{\textbf{fails}}.
  \begin{itemize}
  \item[] (How to interpret $\Lambda \alpha.\lambda x:\alpha.x$?)
  \end{itemize}
  %STORY: explain that no direct "set-theoretic" extension of weakly monotonic functionals
  %STORY: is possible, which is why we use a concrete rewrite system in the interpretation
  %CK: (What is this explanation, though?)

  %LC: It's not trivial, and I don't know it even roughly off the top
  %    of my head. We just mention the well-known (in the type theory
  %    community) paper by Reynolds: ``Polymorphism is not
  %    set-theoretic'', SDT 1984. Essentially, you cannot have a model
  %    of System F where a type A -> B would be interpreted by the set
  %    of all functions from the interpretation of A to the
  %    interpretation of B. Strictly speaking, here we only consider
  %    weakly monotonic functions, but this most probably also
  %    generalises to such a situation. I would need to look into that
  %    to check if this translates verbatim or some more fiddling is
  %    required, but I would be quite surprised if Reynold's argument
  %    didn't work here. In fact, I suspect that it works
  %    ``verbatim'', because the contradiction essentially comes from
  %    some cardinality considerations and weak monotonicity doesn't
  %    seem to save us from cardinality explosion when forming
  %    function spaces.
  %    In short, we can just say it's very unlikely that such a model
  %    exists because of Reynolds' result. Maybe we can say more if I
  %    find time to read the  Reynolds' paper before FSCD.
\item\pause Alternative: use polynomial interpretations to a set of \alert{terms}, not \alert{functions}!
\end{itemize}

\ \\\pause\textbf{Example:}
\[
\begin{array}{rcll}
\nil & : & \forall \alpha. & \List(\alpha) \\
\cons & : & \forall \alpha. & \alpha \arrtype \List(\alpha) \arrtype \List(\alpha) \\
\map & : & \forall \alpha \beta. & (\alpha \arrtype \beta) \arrtype \List(\alpha) \arrtype \List(\beta) \\
\end{array}
\]

\[
\begin{array}{rcll}
\typeinterpret{\List(\alpha)} & = & \alpha \\
\interpret{\nil} & = & \Lambda \alpha. & \lift_\alpha(0) \\
\interpret{\cons} & = & \Lambda \alpha.\lambda xy. & \lift_\alpha(1) \oplus x \oplus y \\
\interpret{\map} & = & \Lambda \alpha\beta.\lambda f x. & (\lift_\beta(2) \oplus \lift_\beta(\flatten_\alpha(x))) \\
  & & & \otimes\ (\lift_\beta(1) \oplus f(x)) \\
\end{array}
\]
\end{frame}

\begin{frame}<1>[label=mainframe]
  \frametitle{Polynomial interpretations: polymorphic higher-order}
  \framesubtitle{Interpretation terms: extension of system~$\Fomega$}
  % STORY: polymorphic lambda calculus with type constructors (system
  % F-omega) extended with the type of natural number and custom
  % operations on natural numbers
  One type constant~$\nat$.\pause

  \medskip

  % STORY: terms are like for PFSs but without the restrictions
  Terms: variables, abstractions, type (constructor) abstractions, and
  function symbols\pause:
  \begin{itemize}
  \item $\oplus : \forall \alpha . \alpha \arrtype \alpha \arrtype
    \alpha$\pause
    \[
    \begin{array}{rcl}
      n \oplus_{\nat} m &\arrW& n+m\\
      s \oplus_{\sigma \arrtype \tau} t &\arrW&
      \abs{x:\sigma}{(\app{s}{x}) \oplus_\tau (\app{t}{x})}\\
      s \oplus_{\quant{\alpha}{\sigma}} t &\arrW&
      \tabs{\alpha}{(\tapp{s}{\alpha}) \oplus_\sigma (\tapp{t}{\alpha})}
    \end{array}
    \]\pause
    % STORY: \oplus is addition: on natural numbers as expected, on
    % functions ``argumentwise''
    % <<HERE COMES THE NEXT SLIDE>>
  \item $\otimes : \forall \alpha . \alpha \arrtype \alpha \arrtype
    \alpha$\pause
    % STORY: \otimes analogous to \oplus
  \item $\flatten : \forall \alpha . \alpha \arrtype \nat$\pause
    \[
    \begin{array}{rcl}
      \app{\flatten_\nat}{s} &\arrW& s\\
      \app{\flatten_{\sigma \arrtype \tau}}{s} &\arrW& \app{\flatten_\tau}{(\app{s}{(\app{\lift_\sigma}{0})})}\\
      \app{\flatten_{\quant{\alpha}{\sigma}}}{s} &\arrW& \app{\flatten_{\sigma[\subst{\alpha}{\nat}]}}{(\tapp{s}{\nat})}
    \end{array}
    \]\pause
    % STORY: \flatten allows ...
    % STORY: note that the reductions for \flatten get stuck on type variables
  \item $\lift : \forall \alpha . \nat \arrtype \alpha$\pause
    \[
    \begin{array}{rcl}
      \app{\lift_\nat}{s} &\arrW& s\\
      \app{\lift_{\sigma \arrtype \tau}}{s} &\arrW& \abs{x:\sigma}{\app{\lift_{\tau}}{s}}\\
      \app{\lift_{\quant{\alpha}{\sigma}}}{s} &\arrW& \tabs{\alpha}{\app{\lift_{\sigma}}{s}}
    \end{array}
    \]
  \end{itemize}
  % STORY: we also have beta-reductions, also for type constructor abstraction, not shown here
\end{frame}

\againframe<2>[noframenumbering]{mainframe}
\againframe<3>[noframenumbering]{mainframe}
\againframe<4>[noframenumbering]{mainframe}

\begin{frame}[noframenumbering]
  % STORY: an inductive definition is not possible because of type
  % abstractions: how is \oplus_\alpha to be interpreted in \Lambda
  % \alpha . \oplus_\alpha s t?
  \begin{center}
    $\Lambda \alpha . x \oplus_\alpha y$
  \end{center}
  \pause
  \bigskip
  \[
  (\Lambda \alpha . x \oplus_\alpha y) \tau \leadsto x \oplus_\tau y
  \]
\end{frame}

\againframe<5>[noframenumbering]{mainframe}
\againframe<6>[noframenumbering]{mainframe}
\againframe<7>[noframenumbering]{mainframe}
\againframe<8>[noframenumbering]{mainframe}
\againframe<9>[noframenumbering]{mainframe}

\begin{frame}{Polynomial interpretations: polymorphic higher-order}
  \framesubtitle{Interpretation terms: extension of system~$\Fomega$}
  \begin{theorem}
    The reduction relation $\leadsto$ is terminating.
  \end{theorem}
  % STORY: the termination proof method is standard (Tait-Girard,
  % computability, candidates), but the question itself subtle because
  % of the ``matching'' on types (go back to flatten and lift)
  \pause
  \begin{corollary}
    All closed normal interpretation terms of type $\nat$ are natural
    numbers.
  \end{corollary}
\end{frame}

\begin{frame}{The well-founded order}
  The relation $s \succ_{\sigma} t$ is defined coinductively by:
  \[
  \begin{array}{c}
    \infer={s \succ_\nat t}{s\da > t\da \text{ in }\mathbb{N}} \\ \\
    \infer={s \succ_{\sigma\arrtype\tau} t}{\app{s}{q} \succ_{\tau} \app{t}{q} \text{ for all } q \in \Iterms^f_\sigma} \\ \\
    \infer={s \succ_{\forall(\alpha:\kappa).\sigma} t}{\tapp{s}{\tau} \succ_{\nf_\beta(\sigma[\subst{\alpha}{\tau}])} \tapp{t}{\tau} \text{ for all closed } \tau \in \Tc_{\kappa}}
  \end{array}
  \]
  % STORY: say this should be interpreted as: s \succ t holds if this
  % can be justified using a possibly infinite proof built from the
  % rules above

  % STORY: more precisely, we define \succ for closed terms by
  % coinduction, and the lift this to arbitrary terms (uninteresting
  % details)

  % STORY: \da means taking the normal form; because the terms are
  % closed the normal forms must be natural numbers by the corollary,
  % so we can just compare them with the order on natural numbers
\end{frame}

\begin{frame}{The well-founded order}
  \framesubtitle{Example derivation}
  \[
  \infer={s \oplus \lift_{\nat\to\nat}(1) \succ_{\nat\to\nat} s}{
    \infer={(s \oplus \lift_{\nat\to\nat}(1)) u \succ_\nat s u \text{ for any } u \in \Iterms^f_\nat}{
      ((s \oplus \lift_{\nat\to\nat}(1)) u)\da > (su)\da \text{ for any } u \in \Iterms^f_\nat
    }
  }
  \]

  \bigskip
  \pause

  $((s \oplus \lift_{\nat\to\nat}(1)) u)\da > (su)\da$ holds because
  \[
  (s \oplus \lift_{\nat\to\nat}(1)) u \leadsto^+ su \oplus \lift_{\nat\to\nat}(1) u \leadsto^+ su \oplus 1
  \]
\end{frame}

\begin{frame}{The well-founded order}
  \framesubtitle{Infinite derivations}
  In any derivation of $s \succ_{\forall\alpha . \alpha} t$ there is an infinite branch.
  \[
  \infer={s \succ_{\forall \alpha . \alpha} t}{
    \infer={\tapp{s}{\forall\alpha.\alpha} \succ_{\forall \alpha . \alpha} \tapp{t}{\forall\alpha.\alpha}}{
      \infer={\tapp{\tapp{s}{\forall\alpha.\alpha}}{
          \forall \alpha . \alpha} \succ_{\forall \alpha . \alpha}\tapp{\tapp{t}{\forall\alpha.\alpha}}{\forall\alpha.\alpha}}{\vdots} &
      \ldots} &
    \ldots
  }
  \]
  % STORY: the need for infinite derivations comes from the
  % impredicative universal type quantifier
\end{frame}

\begin{frame}{The well-founded order}
  \begin{lemma}
    $\succ$ is well-founded
  \end{lemma}

  \pause

  \begin{lemma}[compatibility]
    $\succeq$ and~$\succ$ are compatible, i.e., $\succ \cdot
    \succeq\ \subseteq\ \succ$ and $\succeq \cdot
    \succ\ \subseteq\ \succ$.
  \end{lemma}

  \pause

  \begin{lemma}[weak monotonicity]
    If $s \succeq s'$ then $t[\subst{x}{s}] \succeq t[\subst{x}{s'}]$.
  \end{lemma}
\end{frame}

%=================================================

\begin{frame}{Reduction pair}
  We consider again $A$-terms of a fixed PFS~$A$.\pause

  \begin{definition}
    A binary relation~$R$ on $A$-terms is \emph{monotonic} if $R(s, t)$
    implies $R(C[s], C[t])$ for every context~$C$ (we assume $s,t$ have
    the same type~$\sigma$).

    A \emph{reduction pair} is a pair~$(\succeq^A,\succ^A)$ of a
    quasi-order~$\succeq^A$ on $A$-terms and a well-founded
    ordering~$\succ^A$ on $A$-terms such that:
    \begin{itemize}
    \item
      $\succeq^A$ and~$\succ^A$ are compatible, i.e., ${\succ^A} \cdot
      {\succeq^A} \subseteq {\succ^A}$ and ${\succeq^A} \cdot {\succ^A}
      \subseteq {\succ^A}$, and
    \item $\succeq^A$ and~$\succ^A$ are both monotonic.
    \end{itemize}
  \end{definition}
\end{frame}

\begin{frame}{Symbol mapping and interpretation pair}
  \begin{definition}
    A \emph{type constructor mapping} is a function $\Typemap$ which
    maps each type constructor symbol to a closed interpretation type
    constructor of the same kind. A fixed type constructor mapping
    $\Typemap$ is extended inductively to a function from type
    constructors to closed interpretation type constructors in the
    expected way. We denote the extended \emph{interpretation (type)
      mapping} by~$\typeinterpret{\sigma}$. Thus,
    e.g.~$\typeinterpret{\quant{\alpha}{\sigma}} =
    \quant{\alpha}{\typeinterpret{\sigma}}$ and $\typeinterpret{\sigma
      \arrtype \tau} = \typeinterpret{\sigma} \arrtype
    \typeinterpret{\tau}$.
  \end{definition}

  \begin{definition}
    Given a fixed type constructor mapping~$\Typemap$, a \emph{symbol
      mapping} is a function $\Termmap$ which assigns to each function
    symbol $\mathtt{f} : \rho$ a closed interpretation term
    $\Termmap(\mathtt{f})$ of type~$\typeinterpret{\rho}$. We inductively extend a
    symbol mapping $\Termmap$ to an \emph{interpretation
      mapping} $\interpret{s}$ on $A$-terms.
  \end{definition}

  \begin{definition}
    For a fixed type constructor mapping $\Typemap$ and symbol mapping
    $\Termmap$, the \emph{interpretation pair}
    $(\succeqinterpret,\succinterpret)$ is defined as follows: $s
    \succeqinterpret t$ if $\interpret{s} \succeq \interpret{t}$, and $s
    \succinterpret t$ if $\interpret{s} \succ \interpret{t}$.
  \end{definition}
\end{frame}

\begin{frame}{Safety}
  \begin{definition}
    If $s_1 \succ s_2$ implies $t[\subst{x}{s_1}] \succ
    t[\subst{x}{s_2}]$, then the interpretation term~$t$ is \emph{safe
      for~$x$}. A symbol mapping~$\Termmap$ is \emph{safe} if for all
    \[
    \mathtt{f} : \forall (\alpha_1 : \kappa_1) \ldots \forall
    (\alpha_n : \kappa_n) . \sigma_1 \arrtype \ldots \arrtype \sigma_k
    \arrtype \tau
    \]
    with~$\tau$ a type atom we have: $\Termmap(\mathtt{f}) =
    \tabs{\alpha_1 \dots \alpha_n}{\abs{x_1 \dots x_k}{t}}$ with $t$
    safe for each~$x_i$.
  \end{definition}

  \pause

  \begin{enumerate}
  \item $x u_1 \ldots u_m$ is safe for~$x$.
  \item If $t$ is safe for~$x$ then so are~$\lift(t)$
    and~$\flatten(t)$.
  \item If $s_1$ is safe for~$x$ or $s_2$ is safe for~$x$ then $s_1
    \oplus s_2$ is safe for~$x$.
  \item If either
      (a)
      $s_1$ is safe for~$x$ and $s_2 \succeq \lift(1)$, or
      (b)
      $s_2$ is safe for~$x$ and $s_1 \succeq \lift(1)$,
    then $s_1 \otimes s_2$ is safe for~$x$.
  \item If~$t$ is safe for~$x$ then so is~$\tabs{\alpha}{t}$
    and~$\abs{y}{t}$ ($y \ne x$).
  \end{enumerate}

  \pause

  \begin{theorem}
    If~$\Termmap$ is safe then the interpretation pair
    $(\succeqinterpret,\succinterpret)$ is a reduction pair.
  \end{theorem}
\end{frame}

\begin{frame}{Rule removal}
\end{frame}

\begin{frame}{Results}
\end{frame}

\begin{frame}{Conclusions and future work}
\end{frame}


\end{document}
